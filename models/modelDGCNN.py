"""
Dynamic Graph CNN –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ LiDAR –¥–∞–Ω–Ω—ã—Ö
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


# ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ====================

def knn(x, k):
    """
    K-Nearest Neighbors –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    Args:
        x: (B, C, N) - —Ç–æ—á–∫–∏
        k: —á–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π
    Returns:
        idx: (B, N, k) - –∏–Ω–¥–µ–∫—Å—ã k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
    """
    inner = -2 * torch.matmul(x.transpose(2, 1), x)  # (B, N, N)
    xx = torch.sum(x**2, dim=1, keepdim=True)  # (B, 1, N)
    pairwise_distance = -xx - inner - xx.transpose(2, 1)  # (B, N, N)
    
    idx = pairwise_distance.topk(k=k, dim=-1)[1]  # (B, N, k)
    return idx


def get_graph_feature(x, k=20, idx=None, dim9=False):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (EdgeConv)
    Args:
        x: (B, C, N)
        k: —á–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π
        idx: –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã —Å–æ—Å–µ–¥–µ–π
        dim9: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ 9D –ø—Ä–∏–∑–Ω–∞–∫–∏ (xyz + –ø—Ä–∏–∑–Ω–∞–∫–∏)
    Returns:
        feature: (B, 2C, N, k) - –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–±–µ—Ä –≥—Ä–∞—Ñ–∞
    """
    batch_size = x.size(0)
    num_points = x.size(2)
    x = x.view(batch_size, -1, num_points)
    
    if idx is None:
        if dim9 == False:
            idx = knn(x, k=k)  # (B, N, k)
        else:
            idx = knn(x[:, 6:], k=k)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ xyz –¥–ª—è KNN
    
    device = x.device
    
    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1) * num_points
    idx = idx + idx_base
    idx = idx.view(-1)
    
    _, num_dims, _ = x.size()
    
    x = x.transpose(2, 1).contiguous()  # (B, N, C)
    feature = x.view(batch_size * num_points, -1)[idx, :]  # (B*N*k, C)
    feature = feature.view(batch_size, num_points, k, num_dims)  # (B, N, k, C)
    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)  # (B, N, k, C)
    
    feature = torch.cat((feature - x, x), dim=3).permute(0, 3, 1, 2).contiguous()
    # (B, 2C, N, k) - [—Ä–∞–∑–Ω–æ—Å—Ç—å —Å–æ—Å–µ–¥–µ–π, —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞]
    
    return feature


# ==================== DGCNN LAYERS ====================

class EdgeConvBlock(nn.Module):
    """
    Edge Convolution Block
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥—Ä–∞—Ñ–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏ –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç k —Å–æ—Å–µ–¥–µ–π
    """
    def __init__(self, in_channels, out_channels, k=20):
        super().__init__()
        self.k = k
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels * 2, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(negative_slope=0.2)
        )
    
    def forward(self, x):
        """
        x: (B, C, N)
        return: (B, out_channels, N)
        """
        x = get_graph_feature(x, k=self.k)  # (B, 2C, N, k)
        x = self.conv(x)  # (B, out_channels, N, k)
        x = x.max(dim=-1, keepdim=False)[0]  # (B, out_channels, N)
        return x


# ==================== DGCNN MODEL ====================

class DGCNN_LiDAR(nn.Module):
    """
    DGCNN –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ LiDAR –¥–∞–Ω–Ω—ã—Ö
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    1. Feature Extraction: 4 EdgeConv –±–ª–æ–∫–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –∫–∞–Ω–∞–ª–æ–≤
       - EdgeConv1: in ‚Üí 64 (k=20)
       - EdgeConv2: 64 ‚Üí 64 (k=20)
       - EdgeConv3: 64 ‚Üí 128 (k=20)
       - EdgeConv4: 128 ‚Üí 256 (k=20)
    
    2. Global Feature Aggregation: Conv1d –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π
       - Concat –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 64+64+128+256 = 512
       - Conv1d: 512 ‚Üí 1024
    
    3. Decoder: MLP –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
       - Concat –ª–æ–∫–∞–ª—å–Ω—ã—Ö + –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö: 1024+512 = 1536
       - Conv1d: 1536 ‚Üí 512 ‚Üí 256 ‚Üí 128
       - Output: 128 ‚Üí num_classes
    
    –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: LeakyReLU(0.2)
    Dropout: 0.5 –ø–µ—Ä–µ–¥ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Å–ª–æ–µ–º
    """
    
    def __init__(self, num_classes=4, k=20, use_features=True, feature_dim=3, dropout=0.5):
        """
        Args:
            num_classes: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            k: —á–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π –¥–ª—è KNN
            use_features: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (intensity, returns)
            feature_dim: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–æ–ø. –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            dropout: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout
        """
        super().__init__()
        
        self.k = k
        self.num_classes = num_classes
        self.use_features = use_features
        
        # –í—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 3 (xyz) + feature_dim (intensity, returns, etc.)
        input_channels = 3 + (feature_dim if use_features else 0)
        
        # ========== ENCODER: Edge Convolutions ==========
        # –ë–ª–æ–∫ 1: input ‚Üí 64
        self.edgeconv1 = EdgeConvBlock(input_channels, 64, k=k)
        
        # –ë–ª–æ–∫ 2: 64 ‚Üí 64
        self.edgeconv2 = EdgeConvBlock(64, 64, k=k)
        
        # –ë–ª–æ–∫ 3: 64 ‚Üí 128
        self.edgeconv3 = EdgeConvBlock(64, 128, k=k)
        
        # –ë–ª–æ–∫ 4: 128 ‚Üí 256
        self.edgeconv4 = EdgeConvBlock(128, 256, k=k)
        
        # ========== GLOBAL FEATURE AGGREGATION ==========
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —É—Ä–æ–≤–Ω–∏: 64 + 64 + 128 + 256 = 512
        self.conv_global = nn.Sequential(
            nn.Conv1d(512, 1024, kernel_size=1, bias=False),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(negative_slope=0.2)
        )
        
        # ========== DECODER: Segmentation Head ==========
        # Concat: global (1024) + local (512) = 1536
        self.conv_decode1 = nn.Sequential(
            nn.Conv1d(1536, 512, kernel_size=1, bias=False),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(negative_slope=0.2)
        )
        
        self.conv_decode2 = nn.Sequential(
            nn.Conv1d(512, 256, kernel_size=1, bias=False),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(negative_slope=0.2)
        )
        
        self.dp = nn.Dropout(p=dropout)
        
        self.conv_decode3 = nn.Sequential(
            nn.Conv1d(256, 128, kernel_size=1, bias=False),
            nn.BatchNorm1d(128),
            nn.LeakyReLU(negative_slope=0.2)
        )
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.conv_out = nn.Conv1d(128, num_classes, kernel_size=1)
    
    def forward(self, x):
        """
        Args:
            x: (B, N, C) –≥–¥–µ C = 3 + feature_dim (xyz + intensity, returns, etc.)
        Returns:
            (B, N, num_classes) - –ª–æ–≥–∏—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        """
        B, N, C = x.shape
        
        # Transpose –¥–ª—è Conv1d/Conv2d: (B, N, C) ‚Üí (B, C, N)
        x = x.transpose(2, 1).contiguous()  # (B, C, N)
        
        # ========== ENCODER ==========
        x1 = self.edgeconv1(x)      # (B, 64, N)
        x2 = self.edgeconv2(x1)     # (B, 64, N)
        x3 = self.edgeconv3(x2)     # (B, 128, N)
        x4 = self.edgeconv4(x3)     # (B, 256, N)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        x_local = torch.cat((x1, x2, x3, x4), dim=1)  # (B, 512, N)
        
        # ========== GLOBAL FEATURES ==========
        x_global = self.conv_global(x_local)  # (B, 1024, N)
        
        # Max pooling –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        x_global_max = x_global.max(dim=-1, keepdim=True)[0]  # (B, 1024, 1)
        x_global_max = x_global_max.repeat(1, 1, N)  # (B, 1024, N)
        
        # ========== DECODER ==========
        # Concatenate –ª–æ–∫–∞–ª—å–Ω—ã–µ + –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        x_concat = torch.cat((x_local, x_global_max), dim=1)  # (B, 1536, N)
        
        x = self.conv_decode1(x_concat)  # (B, 512, N)
        x = self.conv_decode2(x)         # (B, 256, N)
        x = self.dp(x)
        x = self.conv_decode3(x)         # (B, 128, N)
        x = self.conv_out(x)             # (B, num_classes, N)
        
        # Transpose –æ–±—Ä–∞—Ç–Ω–æ: (B, num_classes, N) ‚Üí (B, N, num_classes)
        x = x.transpose(2, 1).contiguous()
        
        return x


# ==================== SUMMARY FUNCTION ====================

def model_summary(model, input_size=(2, 4096, 6), device='cuda'):
    """
    –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
    """
    model = model.to(device)
    
    print("=" * 80)
    print(f"{'DGCNN MODEL SUMMARY':^80}")
    print("=" * 80)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nüìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
    print(f"   –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
    print(f"   –û–±—É—á–∞–µ–º—ã—Ö: {trainable_params:,}")
    print(f"   –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: {total_params * 4 / 1024 / 1024:.2f} MB")
    
    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    print(f"\nüèóÔ∏è  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:")
    print(f"   –ö–ª–∞—Å—Å–æ–≤: {model.num_classes}")
    print(f"   K —Å–æ—Å–µ–¥–µ–π: {model.k}")
    print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {model.use_features}")
    
    print(f"\nüîß –°–ª–æ–∏:")
    print(f"   ‚îå‚îÄ ENCODER (Edge Convolutions):")
    print(f"   ‚îÇ  ‚îú‚îÄ EdgeConv1: input ‚Üí 64 channels")
    print(f"   ‚îÇ  ‚îú‚îÄ EdgeConv2: 64 ‚Üí 64 channels")
    print(f"   ‚îÇ  ‚îú‚îÄ EdgeConv3: 64 ‚Üí 128 channels")
    print(f"   ‚îÇ  ‚îî‚îÄ EdgeConv4: 128 ‚Üí 256 channels")
    print(f"   ‚îÇ")
    print(f"   ‚îú‚îÄ GLOBAL AGGREGATION:")
    print(f"   ‚îÇ  ‚îî‚îÄ Conv1d: 512 ‚Üí 1024 channels")
    print(f"   ‚îÇ")
    print(f"   ‚îî‚îÄ DECODER (Segmentation Head):")
    print(f"      ‚îú‚îÄ Conv1d: 1536 ‚Üí 512 channels")
    print(f"      ‚îú‚îÄ Conv1d: 512 ‚Üí 256 channels")
    print(f"      ‚îú‚îÄ Dropout: p=0.5")
    print(f"      ‚îú‚îÄ Conv1d: 256 ‚Üí 128 channels")
    print(f"      ‚îî‚îÄ Output: 128 ‚Üí {model.num_classes} classes")
    
    print(f"\n‚ö° –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: LeakyReLU(negative_slope=0.2)")
    print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: BatchNorm2d/BatchNorm1d")
    
    # –¢–µ—Å—Ç forward pass
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ forward pass...")
    x = torch.randn(input_size).to(device)
    with torch.no_grad():
        out = model(x)
    
    print(f"   Input shape:  {x.shape}")
    print(f"   Output shape: {out.shape}")
    print(f"   ‚úÖ Forward pass —É—Å–ø–µ—à–µ–Ω!")
    
    print("=" * 80)


# ==================== TESTING ====================

if __name__ == '__main__':
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DGCNN –¥–ª—è LiDAR —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    num_classes = 4
    k = 20
    use_features = True
    feature_dim = 3  # intensity, return_number, number_of_returns
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = DGCNN_LiDAR(
        num_classes=num_classes,
        k=k,
        use_features=use_features,
        feature_dim=feature_dim,
        dropout=0.5
    )
    
    # Summary
    input_channels = 3 + (feature_dim if use_features else 0)
    model_summary(model, input_size=(2, 4096, input_channels), device=device)
    
    # –¢–µ—Å—Ç backward
    print(f"\nüî¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ backward pass...")
    model.train()
    x = torch.randn(2, 4096, input_channels).to(device)
    labels = torch.randint(0, num_classes, (2, 4096)).to(device)
    
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    optimizer.zero_grad()
    out = model(x)
    loss = criterion(out.view(-1, num_classes), labels.view(-1))
    loss.backward()
    optimizer.step()
    
    print(f"   Loss: {loss.item():.4f}")
    print(f"   ‚úÖ Backward pass —É—Å–ø–µ—à–µ–Ω!")
    
    print("\n" + "=" * 80)
    print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´")
    print("=" * 80)